{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "import re\n",
    "def build_vocab(sentences, verbose=True):\n",
    "    vocab = {}\n",
    "    for i in trange(len(sentences)):\n",
    "        for word in re.split(',| ', sentences[i]):\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train+Val row data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open('data/train/train_label.txt', 'r') as f:\n",
    "    data_train = ['data/train/train_images/'+line.strip().strip('.') for line in f.readlines()]\n",
    "with open('data/val/val_label.txt', 'r') as f:\n",
    "    data_val = ['data/val/val_images/'+line.strip().strip('.') for line in f.readlines()]\n",
    "data = data_train+data_val\n",
    "train_cars = []\n",
    "train_peoples = []\n",
    "train_cars_path = []\n",
    "train_peoples_path = []\n",
    "train_cars_code = []\n",
    "train_peoples_code = []\n",
    "for line in data:\n",
    "    if any(s.isdigit() for s in line):\n",
    "        train_peoples.append(line.split('$')[-1])\n",
    "        train_peoples_path.append(line.split('$')[0])\n",
    "        train_peoples_code.append(line.split('$')[1])\n",
    "    else:\n",
    "        train_cars.append(line.split('$')[-1])\n",
    "        train_cars_path.append(line.split('$')[0])\n",
    "        train_cars_code.append(line.split('$')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test row data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "with open('data/test/test_text.txt', 'r') as f:\n",
    "    data = [line.strip().strip('.') for line in f.readlines()]\n",
    "test_peoples = [d for d in data if (' female' in d or ' woman' in d or ' male' in d or ' man' in d)]\n",
    "test_cars = [d for d in data if not (' female' in d or ' woman' in d or ' male' in d or ' man' in d)]\n",
    "# test_cars = data[:7611]\n",
    "# test_peoples = data[7611:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train code (people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img_path':train_peoples_path})\n",
    "df['code'] = -1\n",
    "for i, code in enumerate(train_peoples_code):\n",
    "    code = [int(j) for j in code.split(',')]\n",
    "    new_code = []\n",
    "    if code[0] == 1:\n",
    "        new_code.extend([1,0])\n",
    "    else:\n",
    "        new_code.extend([0,1])\n",
    "    if code[1] == 1:\n",
    "        new_code.extend([1,0,0])\n",
    "    elif code[2] == 1:\n",
    "        new_code.extend([0,1,0])\n",
    "    elif code[3] == 1:\n",
    "        new_code.extend([0,0,1])\n",
    "    if code[4] == 1:\n",
    "        new_code.extend([1,0,0])\n",
    "    elif code[5] == 1:\n",
    "        new_code.extend([0,1,0])\n",
    "    elif code[6] == 1:\n",
    "        new_code.extend([0,0,1])\n",
    "    if code[7] == 1:\n",
    "        new_code.extend([1,0])\n",
    "    else:\n",
    "        new_code.extend([0,1])\n",
    "    if code[8] == 1:\n",
    "        new_code.extend([1,0])\n",
    "    else:\n",
    "        new_code.extend([0,1])\n",
    "    if code[9] == 1:\n",
    "        new_code.extend([1,0])\n",
    "    else:\n",
    "        new_code.extend([0,1])\n",
    "    if code[10] == 1:\n",
    "        new_code.extend([1,0,0])\n",
    "    elif code[11] == 1:\n",
    "        new_code.extend([0,1,0])\n",
    "    else:\n",
    "        new_code.extend([0,0,1])\n",
    "    if code[12] == 1:\n",
    "        new_code.extend([1,0])\n",
    "    else:\n",
    "        new_code.extend([0,1])\n",
    "    if code[13] == 1:\n",
    "        new_code.extend([1,0])\n",
    "    elif code[14] == 1:\n",
    "        new_code.extend([0,1])\n",
    "    if code[15] == 1:\n",
    "        new_code.extend([1,0,0,0,0])\n",
    "    elif code[16] == 1:\n",
    "        new_code.extend([0,1,0,0,0])\n",
    "    elif code[17] == 1:\n",
    "        new_code.extend([0,0,1,0,0])\n",
    "    elif code[18] == 1:\n",
    "        new_code.extend([0,0,0,1,0])\n",
    "    else:\n",
    "        new_code.extend([0,0,0,0,1])\n",
    "    if code[19] == 1:\n",
    "        new_code.extend([1,0])\n",
    "    else:\n",
    "        new_code.extend([0,1])\n",
    "    if code[20] == 1:\n",
    "        new_code.extend([1,0])\n",
    "    else:\n",
    "        new_code.extend([0,1])\n",
    "    if sum(new_code)!=12:\n",
    "        raise NameError('new_code is wrong')\n",
    "    df.loc[i, 'code'] = str(new_code)\n",
    "df.to_csv('data/train_val_peoples.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 0: female/woman\n",
    "# # 1,2,3: elder, adult, youger\n",
    "# # 4,5,6: face, sideway, back\n",
    "# # 7: hat\n",
    "# # 8: glasses\n",
    "# # 9: handbag\n",
    "# # 10,11:shoulderbag, backpack (could be all 0)\n",
    "# # 12: holds objects in front\n",
    "# # 13,14: short sleeves, long sleeves\n",
    "# # 15,16,17,18: upper stripe, upper logo, upper plaid, upper splice (could be all 0)\n",
    "# # 19: coat\n",
    "# # 20: skirt or dress\n",
    "# num = 0\n",
    "# index = 6\n",
    "# sentences = []\n",
    "# for i, code in enumerate(train_peoples_code):\n",
    "#     code_splits = [int(j) for j in code.split(',')]\n",
    "#     cap = train_peoples[i]\n",
    "#     # if code_splits[index] == 1 and ('body back to the camera' not in cap):\n",
    "#     #     print(code_splits, train_peoples[i])\n",
    "#     #     sentences.append(train_peoples[i])\n",
    "#     #     num += 1\n",
    "#     if code_splits[index] != 1 and ('body back to the camera' in cap):\n",
    "#         print(code_splits, train_peoples[i])\n",
    "#         num += 1\n",
    "# print(num)\n",
    "# vocab = build_vocab(sentences)\n",
    "# print(f\"There are {len(vocab)} unique words\")\n",
    "# vocab.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make test code (people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_codes = np.zeros((len(test_peoples), 30), dtype=np.int32)\n",
    "# 0-1, 2-4, 5-7, 8-9, 10-11, 12-13, 14-16, 17-18, 19-20, 21-25, 26-27, 28-29\n",
    "for idx, cap in enumerate(test_peoples):\n",
    "    if ' female' in cap or ' woman' in cap:\n",
    "        test_codes[idx, 0] = 1\n",
    "    else:\n",
    "        test_codes[idx, 1] = 1\n",
    "\n",
    "    if 'aged 60 or older' in cap or 'over 60' in cap or 'at least 60 years old' in cap:\n",
    "        test_codes[idx, 2] = 1\n",
    "    elif 'between 18 and 60 years old' in cap or 'aged 18-60' in cap:\n",
    "        test_codes[idx, 3] = 1\n",
    "    elif 'is a minor' in cap or 'age 18 or younger' in cap or 'not an adult' in cap or 'less than 18 years old' in cap:\n",
    "        test_codes[idx, 4] = 1\n",
    "\n",
    "    if 'body facing the camera' in cap:\n",
    "        test_codes[idx, 5] = 1\n",
    "    elif 'standing sideways' in cap:\n",
    "        test_codes[idx, 6] = 1\n",
    "    elif 'body back to the camera' in cap:\n",
    "        test_codes[idx, 7] = 1\n",
    "\n",
    "    if 'wearning a hat' in cap:\n",
    "        test_codes[idx, 8] = 1\n",
    "\n",
    "    if 'glasses' in cap:\n",
    "        test_codes[idx, 10] = 1\n",
    "\n",
    "    if 'handbag' in cap:\n",
    "        test_codes[idx, 12] = 1\n",
    "\n",
    "    if 'shoulderbag' in cap or 'is carrying a shoulder bag' in cap or 'has a bag over the shoulder' in cap: #some captinos is wrong, code is right, num=2280\n",
    "        test_codes[idx, 14] = 1\n",
    "    elif 'backpack' in cap: #some captinos is wrong, code is right, num=636\n",
    "        test_codes[idx, 15] = 1\n",
    "\n",
    "    if 'holds objects in front' in cap: #some captinos is wrong, code is right, num=155\n",
    "        test_codes[idx, 17] = 1\n",
    "\n",
    "    if 'short sleeve' in cap: #some captinos is wrong, code is right, num=8092\n",
    "        test_codes[idx, 19] = 1\n",
    "    elif 'long sleeve' in cap: #some captinos is wrong, code is right, num=15026\n",
    "        test_codes[idx, 20] = 1\n",
    "\n",
    "    if 'upper stripe' in cap: #some captinos is wrong, code is right, num=677\n",
    "        test_codes[idx, 21] = 1\n",
    "    elif 'upper logo' in cap or 'logo on the upper' in cap: #some captinos is wrong, code is right, num=2214\n",
    "        test_codes[idx, 22] = 1\n",
    "    elif 'upper plaid' in cap or 'plaid on the upper' in cap: #some captinos is wrong, code is right, num=1520\n",
    "        test_codes[idx, 23] = 1\n",
    "    elif 'upper splice' in cap or 'splice on the upper' in cap: #some captinos is wrong, code is right, num=708\n",
    "        test_codes[idx, 24] = 1\n",
    "\n",
    "    if 'coat' in cap:\n",
    "        test_codes[idx, 26] = 1\n",
    "\n",
    "    if 'skirt or dress' in cap: #some captinos is wrong, code is right, num=887\n",
    "        test_codes[idx, 28] = 1\n",
    "\n",
    "code_str = [str(code) for code in test_codes]\n",
    "df = pd.DataFrame({'prompt':test_peoples, 'code':code_str})\n",
    "df.to_csv('data/test/test_people.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique words statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_train_cars = build_vocab(train_cars)\n",
    "print(f\"There are {len(vocab_train_cars)} unique words in train_cars\")\n",
    "vocab_train_peoples = build_vocab(train_peoples)\n",
    "print(f\"There are {len(vocab_train_peoples)} unique words in train_peoples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_test_cars = build_vocab(test_cars)\n",
    "print(f\"There are {len(vocab_test_cars)} unique words in test_cars\")\n",
    "vocab_test_peoples = build_vocab(test_peoples)\n",
    "print(f\"There are {len(vocab_test_peoples)} unique words in test_peoples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert vocab_train_cars.keys() == vocab_test_cars.keys()\n",
    "assert vocab_train_peoples.keys() == vocab_test_peoples.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car cap to code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "car_types = []\n",
    "car_colors = []\n",
    "car_brands = []\n",
    "for cap in test_cars:\n",
    "    s = cap.split()\n",
    "    type_ = s[-1]\n",
    "    if type_ not in car_types:\n",
    "        car_types.append(type_)\n",
    "    for c in s:\n",
    "        if c!='is' and c!='a' and c!='an' and c.islower():\n",
    "            color = c\n",
    "            if color not in car_colors:\n",
    "                car_colors.append(color)\n",
    "    brand = cap.split(type_)[0].split(color)[-1].strip()\n",
    "    if brand not in car_brands:\n",
    "        car_brands.append(brand)\n",
    "\n",
    "print('num_car_type:', len(car_types))\n",
    "print('num_car_colors:', len(car_colors))\n",
    "print('num_car_brands:', len(car_brands))\n",
    "df1 = pd.DataFrame({'type_name':car_types})\n",
    "df2 = pd.DataFrame({'color_name':car_colors})\n",
    "df3 = pd.DataFrame({'brand_name':car_brands})\n",
    "df1.to_csv('data/car_text/car_types.csv', index=False)\n",
    "df2.to_csv('data/car_text/car_colors.csv', index=False)\n",
    "df3.to_csv('data/car_text/car_brands.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'img_path':train_cars_path})\n",
    "df1 = pd.read_csv('data/car_text/car_types.csv')\n",
    "df2 = pd.read_csv('data/car_text/car_colors.csv')\n",
    "df3 = pd.read_csv('data/car_text/car_brands.csv')\n",
    "types = df1['type_name'].tolist()\n",
    "colors = df2['color_name'].tolist()\n",
    "brands = df3['brand_name'].tolist()\n",
    "df['type_name'] = np.nan\n",
    "df['color_name'] = np.nan\n",
    "df['brand_name'] = np.nan\n",
    "df['type'] = np.nan\n",
    "df['color'] = np.nan\n",
    "df['brand'] = np.nan\n",
    "for i, code in enumerate(train_cars):\n",
    "    for t in types:\n",
    "        if t in code:\n",
    "            df.loc[i, 'type_name'] = t\n",
    "            df.loc[i, 'type'] = types.index(t)\n",
    "    for c in colors:\n",
    "        if c in code:\n",
    "            df.loc[i, 'color_name'] = c\n",
    "            df.loc[i, 'color'] = colors.index(c)\n",
    "    for b in brands:\n",
    "        if len(b.split()) == 2:\n",
    "            if b in code:\n",
    "                df.loc[i, 'brand_name'] = b\n",
    "                df.loc[i, 'brand'] = brands.index(b)\n",
    "        elif b in code.split():\n",
    "            df.loc[i, 'brand_name'] = b\n",
    "            df.loc[i, 'brand'] = brands.index(b)\n",
    "df.to_csv('data/train_val_cars.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'prompt':test_cars})\n",
    "df1 = pd.read_csv('data/car_text/car_types.csv')\n",
    "df2 = pd.read_csv('data/car_text/car_colors.csv')\n",
    "df3 = pd.read_csv('data/car_text/car_brands.csv')\n",
    "types = df1['type_name'].tolist()\n",
    "colors = df2['color_name'].tolist()\n",
    "brands = df3['brand_name'].tolist()\n",
    "df['type'] = np.nan\n",
    "df['color'] = np.nan\n",
    "df['brand'] = np.nan\n",
    "for i, code in enumerate(test_cars):\n",
    "    for t in types:\n",
    "        if t in code.split():\n",
    "            df.loc[i, 'type'] = types.index(t)\n",
    "    for c in colors:\n",
    "        if c in code.split():\n",
    "            df.loc[i, 'color'] = colors.index(c)\n",
    "    for b in brands:\n",
    "        if len(b.split()) == 2:\n",
    "            if b in code:\n",
    "                df.loc[i, 'brand'] = brands.index(b)\n",
    "        elif b in code.split():\n",
    "            df.loc[i, 'brand'] = brands.index(b)\n",
    "\n",
    "df.to_csv('data/test/test_car.csv', index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
